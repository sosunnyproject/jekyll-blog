---
layout: default
---


> Translating http://cs231n.github.io/convolutional-networks/ to Korean 스탠포드강의노트 한국어번역중

nonlinear layer = activation layer
depth = 총 Conv의 깊이가 아니라 액티베이션 볼륨의 3번째 차원을 의미한다.

용어 정리
- receptive field: (필터 사이즈와 같은 거지, 필터 자체가 아님) 뉴런과 인풋의 로컬영역을 연결할 때, 그 연결고리의 spatial 범위인 하이퍼파라미터
- spatially: widthxheight 면적에 대해서
- spatial dimensions: widthxheight 차원
- depth dimension: 깊이 차원
- volume: width x height x depth


# Convolutional Neural Networks (CNNs/ConvNets)

CNN은 우리가 이전 장에서 본 일반적인 뉴럴 네트워크와 흡사하다. CNN은 학습하며 업데이트 되는 편향치(bias)와 가중치(weight)를 가진 뉴런으로 구성되어 있다. 

각 뉴런은 몇가지의 인풋을 받은 후, 행렬의 내적(dot product)를 수행하고, 원한다면 non-linearity를 취해줄 수 있다. 이 뉴런들로 큰 하나의 네트워크를 만든다 할지라도, 네트워크는 여전히 하나의(single) 미분가능한 스코어 함수이다: 한쪽은 원본 이미지 픽셀, 다른쪽은 클래스 스코어. 더불어, CNN에서도 마지막 레이어 (fc layer)에 손실 함수 (svm, softmax 등)를 적용한다. 일반적인 뉴럴 네트워크에 썼던 팁/트릭/기법들을 거의 그대로 적용할 수 있다고 생각하면 된다. 

그럼 뭐가 다른걸까? ConvNet 구조에서는 한가지 확실한 가정을 해두고 가야한다. "인풋은 이미지이다. 그리고 우리는 그 이미지들의 특정 속성들을 구조로 인코딩할 수 있어야 한다." 이게 가능해야지 우리가 forward function 을 더 효율적으로 실행할 수 있고, 네트워크의 수많은 파라미터를 확 줄일 수 있다. 

## 구조 훑어보기

#### _일반적인 뉴럴 넷 (신경망)을 기억해보자._
우리가 이전 장에서 보았던 것처럼, 뉴럴 네트워크는 벡터 하나를 인풋으로 받고, 그것을 여러 hidden 레이어들에 통과시켜서 변형한다. 각 hidden 레이어는 여러 뉴런들의 집합으로 구성되어 있다. 이 때 이 hidden 레이어의 뉴런 하나하나는 그 전 레이어의 뉴런들에 모두 빠짐없이 연결되어 있다. 그리고 같은 레이어 안에 있는 뉴런들끼리는 전혀 연결되어 있지 않다. 마지막 fully-connected 레이어는 'output layer' (결과값 레이어)로 불리며, 분류 문제(classification)에서는 이 최종 레이어가 클래스 스코어를 나타낸다. 

일반적인 뉴럴 넷은 큰 이미지 전체 사이즈로 잘 확장할 수가 없다. CIFAR-10에서 이미지들은 32x32x3 (32폭, 32높이, 3 칼라 채널)사이즈 정도 밖에 안된다. 그래서 첫 hidden 레이어에 있는 한개의 뉴런 (fully-connected neuron: 아까 위에서 뉴런은 그 전 애들과 다 연결되어 있다고 했으니까)은 32x32x3 = 3072 개의 가중치를 갖는다. 이 정도면 감당할 수 있을 것처럼 보이는가? 하지만 이런 fully-connected 구조(폭x높이x칼라 다 곱하고 뉴런끼리 다 이어주는 구조...)는 더 큰 이미지 사이즈에는 적용할 수가 없다. 예를 들어, 좀 더 흔히 사용되는 이미지 사이즈는 더 클 것이고, 200x200x3이라고 가정해보자. 그렇다면 200x200x3 = 120,000개의 가중치를 갖는 뉴런이 생기고, 그러한 뉴런들이 모인다면 순식간에 파라미터 개수는 불어날 것이다. 즉, 이러한 full connectivity 는 소모적이며, 수많은 파라미터는 멀지않아 오버피팅을 자초할 것이다.

#### _3차원 볼륨의 뉴런들_

CNN은 _인풋이 이미지로 이루어져 있고 이미지들은 나름 합리적으로 구조를 이루고 있다_ 는 점을 유리하게 이용한다. 일반적인 뉴럴 네트워크와 다르게, ConvNet의 뉴런들은 3차원에 배열되어 있다: 폭, 넓이, 깊이 (여기서 깊이는 활성 volume의 3번째 차원이며, 전체 신경망의 깊이/네트워크의 전체 레이어 개수가 아니다). 예를 들어, CIFAR-10에서 구해오는 인풋 이미지들은 **input volume of activation** 이며, volume은 32x32x3 의 차원을 가지고 있다. 잠시 후에 같이 보겟지만, 레이어의 뉴런들은 이전 레이어에 부분적으로만 연결될 것이다. 그전처럼 fully-connected 되는 것이 아니라. 나아가, CIFAR-10 
을 인풋으로 돌린 네트워크의 마지막 최종 레이어는 1x1x10 차원을 가지게 된다. 왜냐하면 ConvNet 구조의 끝에서는 이미지 통짜 하나를 스코어 클래스를 나타내는 벡터 하나로 줄여버리기 때문이다. 이 때 이 단일 벡터는 depth 차원을 따라서 배열되어 있는 형태이다. (depth 차원의 사이즈를 따른다는 의미로 해석하면 될 것 같다.)

![이미지](http://cs231n.github.io/assets/nn1/neural_net2.jpeg)

> 좌: 일반적인 3층의 신경망 구조. 

> 우: ConvNet 는 자기 뉴런들을 3차원으로 배열한다 (폭, 넓이, 깊이). ConvNet의 각 레이어는 3D 인풋 볼륨을 뉴런들이  활성화된 3D 아웃풋 볼륨으로 바꿔준다. 이 예시에서, 빨강 인풋 레이어가 이미지이고, 빨강의 폭과 넓이는 이미지의 사이즈이다. 그리고 깊이는 빨, 초, 파 칼라 채널이다. 

>> ConvNet은 레이어로 이루어져 있다. 각 레이어는 간단한 API이다. 3차원 인풋을 3차원 아웃풋으로 바꿔준다. 파라미터를 가지고 있을 수도, 아닐 수도 있는, 몇몇 미분 가능한 함수를 이용해서.

## Layers used to build ConvNets ConvNets 만드는 데 필요한 레이어들
위에서 설명했듯이, 간단한 ConvNet (CNN 지칭)은 레이어들의 연속이다. 그리고 각 레이어는 미분 함수를 통해서 _활성화의 한 볼륨_ 을 또다른 것으로 변환시킨다. 우리는 3개의 주요 레이어 타입을 ConvNet 구조에 사용한다: Convolutional Layer, Pooling layer, Fully Connected Layer (바로 일반적인 신경망 네트워크에서 사용하였듯이). 우리는 이런 레이어들을 쌓아서 완전한 ConvNet 구조를 만들 것이다.

**구조 예시: 훑어보기**
아래에서 더 자세히 살펴보겠지만, CIFAR-10 분류를 위한 간단한 ConvNet의 구조는 이렇게 되시겠다: 인풋 - Conv - Relu - Pool - Fc.

자세한 설명:
- 인풋 [32x32x3] 은 이미지의 raw 픽셀값들을 가지고 있다. 이 경우, 폭 32, 높이 32, 색 채널 3이다.
- ConV 레이어는 뉴런들의 아웃풋을 계산한다. 뉴런들은 인풋의 로컬 영역에 연결되어 있고, 각 뉴런은 그들의 가중치와 인풋 로컬영역 간의 행렬 내적곱을 계산한다. 그래서 우리가 만약 12개의 필터를 사용한다치면 [32x32x12] 사이즈의 볼륨을 얻을 것이다.
- RELU 레이어는 elementwise (원소별) 활성화 함수를 사용하는데, max(0,x)계산은 0을 경계점으로 만들어버린다. 이 때, 볼륨의 사이즈(32x32x12)는 바뀌지 않는다.
- 풀링 레이어는 이미지 사이즈를 줄여주는 역할을 한다. 폭과 넓이로 이뤄진 공간 차원을 따라서 사이즈를 축소시켜서 32x32x12를 16x16x12로 바꾸듯이 더 작게 만들어준다.
- FC 레이어는 클래스 스코어를 계산해서 1x1x10 사이즈의 볼륨을 생성한다. CIFAR-10에서 10가지 카테고리가 있는 것처럼, 10개의 숫자들은 클래스 스코어에 해당한다. 일반 뉴럴 네트워크에서 하던 것처럼 (그리고 fully-connected라는 이름이 암시하듯이) 이 레이어의 각 뉴런은 이전 볼륨의 모든 숫자에 연결되어 있다.

이러한 방식으로 ConveNet들은 레이어 하나하나를 거치며 원본 이미지 픽셀 값을 최종 클래스 스코어로 변환한다. 단, 어떤 레이어는 파라미터를 가지고 있고 어떤 것은 그렇지 않다는 것을 주의해라. 특히, ConV/FC 레이어들은 변환을 수행할 때 활성화뿐만 아니라 (가중치와 편향의) 파라미터에 대한 함수들을 사용한다. 다른말로 하자면, RELU/POOL 레이어는 고정 함수를 실행한다. CONV/FC 의 파라미터들은 gradient descent로 인해 학습이 될 것이다. 그렇게 학습을 함으로써, ConvNet이 계산한 클래스 스코어는 트레이닝 데이터 셋에 있는 각 이미지의 클래스 라벨과 동일해야 한다.

요약을 하자면:
- ConvNet 구조는 이미지 볼륨을 어떤 아웃풋 볼륨 (예, 점수 값 보유)으로 변환시켜주는 레이어들의 조합 중 가장 단순한 예시이다.
- 레이어에는 몇가지 기억해둘 타입이 있다: ConV/FC/Relu/Pool이 그 중 제일 유명하다.
- 각 레이어는 3차원 인풋 볼륨을 받고, 미분 함수를 통해서 3차원 아웃품 볼륨을 만든다.
- CONV/FC는 파라미터가 있지만, RELU/Pool은 없다.
- 어떤 레이어는 추가적으로 초파라미터를 가지고 있다. (CONV/FC/Pool은 yes, Relu는 no..)

![이미지](http://cs231n.github.io/assets/cnn/convnet.jpeg)

> ConvNet 구조 에시의 활성화를 보여주는 그림이다. 초기 불륨은 원본 raw 이미지 픽셀 (좌) 을 보유하고 있고, 마지막 볼륨은 클래스 스코어 (우)를 가지고 있다. 일련의 과정을 따라 활성화되는 각 볼륨은 여기서 한 열로 보여지고 있다. 마지막 레이어의 볼륨은 각 클래스에 대한 스코어를 가지고 있지만 이 예시에서는 5개의 고득점 클래스만 시각화했다. 본 웹 데모의 완성판은 우리 웹사이트에서 볼 수 있다. 여기저 보여주는 구조는 작은 VGG 넷 (나중에 설명할 거다)을 쓰고 있다.

우리는 이제 각 레이어와 그들의 하이퍼 파라미터 및 연결고리에 대해서 자세히 알아볼 거다.

### Convolutional 레이어
- Conv 레이어는 Conv 네트어크에서 대부분의 무거운 계산을 책임지는 핵심 요소이다.

**뇌구조 이야기 없이 훑어보기**
우선 Conv Layer에 대해서 뇌구조 비유법은 집어치우고 이야기를 해보자. ConV 레이어의 파라미터는 학습가능한 필터의 집합으로 이루어져 있다. 각 필터는 폭과 높이로 따졌을 때는 작지만 인풋 볼륨 깊이만큼 확장된다/늘어난다. 예를 들어, 보통 첫번째 레이어에 적용하는 필터는 5x5x3 (폭x길이x칼라채널개수이자-깊이)사이즈를 가졌다. forward 계산을 할 때, 각 필터를 인풋 볼륨의 폭과 높이에 대해 슬라이드 시킨다 (더 정확히는 말아 간다 라는 단어가 맞다) 그리고 필터의 값과 인풋 값을 내적한다. 이 슬라이딩 과정에서 우리는 2차원의 활성화 매핑값을 만드는데 각 위치에서 (5x5 마다의 위치) 필터와의 매핑값 결과가 담겨있다.직관적으로 생각한다면, 네트워크는 어떤 특정한 시각 정보를 발견했을 때 활성화되는 필터를 학습할 것이다. 초반의 레이어에서는 엣지(테두리 선)의 방향이나 색깔 뭉탱이를 보다가 나중에는 벌집 모양 전체 혹은 바퀴 모양의 패턴 등을 특징으로 발견할 것이다. 이제 우리는 각 ConV 레이어에 적용한 전체 필터 집합/모음을 가지게 되고 (12 필터), 각 필터는 각기 다른 2차원 활성화 매핑값을 만든다. 우리는 이 활성화 매핑을 깊이를 따라 쌓아서 전체 아웃풋 볼륨을 만들 것이다.

**뇌과학 관점**
네가 정 뇌/뉴런 비유법을 원한다면 알려주지.. 3차원 아웃풋 볼륨의 각 *entry* 는 뉴런의 아웃풋이라고 생각해볼 수도 있다. 어떤 뉴런? 인풋 이미지에서 작은 부분 하나만 보고 좌우에 있는 모든 뉴런과 그 파라미터를 공유하는 아이일 것이다 (왜냐하면 그 숫자들은 같은 필터를 적용해서 나오는 결과값이기 때문에). 우리는 이제 뉴런들의 연결성, 공간에서의 배치도, 공유되는 파라미터들에 대해서 알아볼 것이다.

**지역적 연결성** (너와 나의 연결고리..)
이미지와 같은 고차원 인풋을 가지고 놀 때, 위에서 보앗듯이, 이전 볼륨의 모든 뉴런에다가 지금의 뉴런을 다 연결시키는 건 비실용적인 짓이다. 대신, 우리는 각 뉴런을 인풋 볼륨의 작은 부분만이랑 연결시키고 싶다. 이 연결성을 이미지 공간에 대해서 확장한 것이 뉴런(뉴런의 사이즈는 필터의 사이즈와 같다.)의 receptive field라 불리는 하이퍼 파라미터이다. 깊이 축을 따라 확장한다면 인풋 볼륨의 깊이와 같아지겠지? 이렇게 폭x높이 차원에 대하는 방식과 깊이를 대하는 방식이 다르다는 점, 이 비대칭의 성질은 두번 강조해도 시원찮다. 연결고리는 폭x넓이에 대해서는 지역적이지만, 깊이에 대해서는 전체 깊이 사이즈와 연결되어 있다.

예시1. 32x32x3 사이즈의 인풋 볼륨이 있다고 하자. (CIFAR-10의 RGB 이미지가 그렇다.) 필터 사이즈가 만약 5x5 라면, ConV Layer의 각 뉵런은 5x5x3 사이즈 부분에 대한 가중치를 가져서 토탈 5*5*3 = 75(가중치) + 1(편향) = 76개의 파라미터를 갖는다. 이 때, 이미지의 깊이가 3이니, 깊이 축을 따라 뉴런의 연결고리가 확장되는 사이즈는 반드시 3이어야 한다.

예시2. 16x16x20 사이즈의 인풋이 있다고 생각하자. 필터의 크기는 3x3이다. ConvLayer에 있는 모든 뉴런의 각각 3*3*20 = 180 개의 연결고리를 가지고 있다. 이때 저체 이미지의 3x3 폭x높이 사이즈 마다 한 뉴런이랑 매핑되어 있고, 한 뉴런의 깊이는 20이다.

![이미지](http://cs231n.github.io/assets/cnn/depthcol.jpeg)

> 좌: 빨강색이 인풋 볼륨, ConV의 첫 레이어에 있는 뉴런의 볼륨. 이 레이어의 각 뉴런은 인풋 볼륨의 폭x높이에 대해 지역적으로만(필터 사이즈 만큼씩만) 연결되어 있다. 기억하자: 깊이를 따라 여러 뉴런들이 있고 (여기서는 5), 다 인풋의 같은 지역 부분을 바라보고 있다 - 깊이 열에 대한 설명은 아래에서 이야기하자.

> 우: 뉴럴 네트워크에서 나왔던 뉴런 계산과정은 바뀌지 않았다. 여전히 그들의 가중치들과 인풋의 내적을 계산하고 non-linearity (비선형)을 거친다. 하지만 그들의 연결고리의 범위만 지역으로 제한된 것이다.

**Spatial Arrangement. 공간적 배치** 
Conv 의 각 뉴런이 인풋 볼륨과 연결되어 있다고 몇번을 말했는지 모른다. 하지만 우리는 아직 얼마나 많은 뉴런들이 아웃풋 볼륨에 있는지 혹은 어떻게 배치되어 있는지는 이야기하지 않았다. 아웃풋 볼륨을 결정하는 세가지 파라미터는 다음과 같다: 깊이, 스트라이드(간격), 제로 패딩(0여백)

1. 아웃풋 볼륨의 **깊이** 는 하이퍼 파라미터이다. 깊이는 우리가 사용할 필터의 개수에 상응하는데, 각 필터는 인풋에서 각기 다른 부분을 보고 있다. 예를 들어, 첫 Conv 레이어가 원본 이미지를 인풋으로 받았다. 그리고 깊이 부분에 들어있는 뉴런들은 다양한 방향을 가진 엣지/색깔 뭉탱이들의 존재에 반응하며 활성화될 수도 있다. 우리는 이미지의 같은 로컬부분을 바라보고 있는 뉴런 뭉태기들을 깊이 열 이라고 지칭할거다. (어떤 인간들은 fibre라는 용어를 선호한다. 니맴니맴 내맴내맴)

2. 두번째, 우리는 반드시! 필터를 슬라이드시킬 기준이 되는 스트라이드(간격)를 정해놓고 시작해야 한다. 스트라이드가 1이면 우리는 필터들을 한 번에 한 픽셀씩만 움직인다 (슬라이드시킨다). 스트라이드가 2이면 필터는 한 번에 두 픽셀을 점프해서 다음 로컬 영역으로 넘어간다. (3혹은 그 이상으로 스트라이드 값을 정하는 경우는 드물다.) 이렇게 2씩 점프한다면 아웃풋 볼륨의 폭x높이를 더 작은 사이즈로 만들어 낸다.

3. 아래서 곧 보겠지만, 가끔 인풋 볼륨의 모서리를 따라서 패딩(여백)을 0값들로 채워주는 게 편할 때가 있다. 이 제로 패딩의 사이즈가 하이퍼 파라미터이다. 제로 패딩의 좋은 특징은 이걸 이용해서 아웃풋 볼륨의 spatial size (폭x높이) 사이즈를 조절할 수 있다는 것이다. (잠시 후에 알려주겠지만, 거의 대부분은 인풋 볼륨의 spatial 폭x높이 사이즈를 원본이랑 똑같이 유지할 수 있도록 패딩 사이즈를 준다. 그래야 인풋과 아웃풋의 폭x높이 사이즈가 같아지니까.)

인풋 볼륨 사이즈의 함수(W), Conv 레이어 뉴런들의 필터(혹은 receptive field) 사이즈(F), 적용한 스트라이드 값(S), 모서리에 붙여 쓴 제로 패딩(P)의 양 -- 우리는 이것들을 가지고 아웃풋의 spatial 사이즈를 계산할 수 있다. 얼마나 많은 뉴런이 끼워맞춰지는지를 알고 싶으면 (W-F+2P)/S + 1 수식을 이용하면 된다고 네 뇌를 설득해도 무방하다 (그냥 외워도 된다는 소리다.) 예를 들어, 7x7 인풋, 스트라이드 1, 패딩0 3x3 필터를 쓴다면
(7 - 3 + 2* 0) / 1 + 1 = 4+1 = 5
계산해서 5x5 아웃풋 사이즈를 얻는다.
스트라이드 2라고 가정하면, 3x3 아웃풋이 나온다.
(이 대입 계산 정도는 님이 하시길...)

![이미지](http://cs231n.github.io/assets/cnn/stride.jpeg)

> 공간 배치의 묘사도. 이 예시에서는 공간 차원이 하나, x 축밖에 없고, 하나의 뉴런당 필터 사이즈가 3, 인풋 사이즈는 5, 제로 패딩 1.

> 좌: 인풋에 스트라이드 1 이 적용된 뉴런 --> (5-3+2)/1 +1 =5 아웃풋 사이즈가 나왔다.

> 우: 스트라이드 값을 2를 줬더니, 3이 나왔다. 스트라이드 3값은 쓸수가 없다 - 인풋 볼륨에 깔끔하게 적용이 안되니까. 수식으로 생각해보면, (5-3+2)=4 는 3으로 나눌 수가 없짜나?

> 뉴런 가중치들은 [1,0,-1] (최 우측) 이고, 편향치는 제로라고 생각하자. 이 가중치들은 노랑 뉴런 하나하나에 다 적용된다. (파라미터 공유에 대해서는 아래에서 설명할거다.)

*제로 패딩 사용*
위 이미지의 왼쪽을 보면, 인풋의 차원이 5이고 아웃풋 차원도 5이다. 이게 가능할 수 있는 이유는 필터가 3이었고 제로 패딩으로 1을 주었기 때문이다. 만약 제로 패딩을 쓰지 않았다면 아웃풋 볼륨의 공간 차원은 3이 되었을 것이다. 왜냐하면 원본 인풋에 그만큼밖에 뉴런들이 'fit'할 수 없기 때문이다. 일반적으로, 인풋과 아웃풋의 볼륨의 spatial 사이즈를 똑같게 해주기 위해 스트라이드가 1일 때는 제로 패딩을 P = (F-1)/2 만큼 준다. 이런 식으로 제로 패딩을 사용하는 게 굉장히 흔하며 더 자세한 이유들은 ConvNet 구조 부분에서 다루겠다.

*스트라이드 제약*
하이퍼파라미터를 spatial 배치를 할 때 서로 간의 제약이 있어야 한다는 걸 기억해라. 예를 들어, 인풋의 사이즈가 W = 10, 제로 패딩은 0, 필터 사이즈 F = 3이라면, 스트라이드 값으로 2를 쓸 수는 없다. 왜냐하면 (W-F+2P)/S + 1 = (10-3+0)/2 + 1 = 4.5 가 나오기 때문이다. 이렇게 정수가 아니면 인풋에 뉴런들이 깔끔하고 대칭적으로 'fit'하지 않는다. 그러므로, 이런 식의 하이퍼 파라미터 설정은 불가능하고, ConvNet 라이브러리가 예외 에러를 반환하거나 fit 하기 위해 나머지에 제로 패딩을 주거나, 인풋을 크랍하거나 할 수도 있다. ConvNet 설계 구조 섹션에서 보겠지만, 적절하게 ConvNet들 사이즈를 맞춰줘서 모든 디멘션이 딱 잘 맞아 떨어지게 하는 게 보통 머리아픈 일이 아니다. 이 때, 제로패딩을 사용하거나 레이어 디자인 가이드라인들을 사용하면 고민을 많이 해결할 수 있다. 

*현실 예시 적용*
2012년에 ImageNet 챌린지를 우승한 Krizhevsky 등 저자 논문의 구조를 보면 227x227x3 사이즈의 이미지를 인풋으로 받는다. 첫번째 Conv 레이어에서는 필터사이즈가 F=11, S=4, P=0인 뉴런들을 사용했다. (227-11)/4+1=55가 되니, Conv레이어는 96의 깊이를 가지고, Conv 레이어 아웃풋 볼륨은 55x55x96의 사이즈를 갖게 되었다. 각기 55x55x96 사이즈인 뉴런들은 인풋의 11x11x3 사이즈 영역에 연결되어 있었다. 여기서 각 깊이 열에 있는 96개의 뉴런들은 다같이 같은 11x11x3 영역 부분에 연결되어 있고, 당연히 가중치 값들은 다 다르다. 재밌는 부분은, 이 논문을 제대로 읽었다면 알텐데, 논문에서는 인풋 이미지들이 224x224라고 주장하는데, 그럴 리가 없는 게 (224-11)/4+1 는 아무리 해봐도 정수 값으로 떨어져서 계산이 나오지 않기 때문이다. 이 때문에 ConvNets를 아는 사람들은 헷갈려 했고, 실제로 무슨 일이 있었는지는 잘 모른다. 내가 생각하기엔 Alex가 논문에서 언급하지 않은 제로패딩3 을 추가적으로 사용하지 않았을까 싶다.

**파라미터 공유**
Conv Layers 에서 파라미터의 넘버를 조절하기 위해 파라미터 공유 전략을 사용한다. 위에서 말한 현실적인 예시를 사용하면, Conv 첫번째 레이어에 55x55x96 = 290,400 개의 뉴런들이 있고, 각 뉴런들은 11x11x3 = 363 가중치와 1 편향치를 가지고 있는 것을 알 수 있다. 다 합쳐보면 ConvNet 첫번째 레이어 단 하나에만 무려 290400*364 = 105705600 파라미터들이 존재한다. 딱봐도 겁나 많다.

알고 보니! 우리는 한 가지 합리적인 가정을 만듦으로써 파라미터들의 개수를 엄청 많이 줄일 수 있다. 만약 이미지의 한 특성(엣지/칼라 등)이 어떤 (x,y) 공간 위치에서 유용하다면, 그건 (x2,y2)다른 위치에서도 분명 유용할 것이다.

이러한 파라미터 공유 전략을 이용한다면, 우리 예시에 있는 첫번째 Conv 레이어는 이제 96 개의 가중치 집합 (한 깊이 슬라이스당 한 집합)을 가지게 된다. 총 합계는 96*11*11*3 = 34,848 개의 독자적인 가중치 값 혹은 34,944개의 파라미터 (가중치+편향) 개수. 그게 아니라면, 각 깊이 슬라이스에 들어있는 뉴런들, 다 합친다면 55*55개인 뉴런들이, 모두 같은 파라미터를 쓰게 될 것이다. 오차역전파법을 실제로 쓸 때는, 볼륨마다 들어있는 각 뉴런들이 각자의 가중치의 기울기를 계산할 텐데, 이 기울기들은 깊이 슬라이스들을 따라 다 합쳐져서, 결국에는 한 깊이 슬라이스당 하나의 가중치 집합을 업데이트 할 것이다. 

보아라! 하나의 깊이 슬라이스에 있는 모든 뉴런들이 만약 같은 가중치 벡터를 사용하고 있다면, Conv 레이어의 forward pass는 각 깊이 슬라이스에서 그 안에 있는 뉴런들의 가중치와 인풋 볼륨을 convolution으로 계산할 것이다. (그래서 이름이 Convolutional Layer). 이게 바로 가중치의 집합을 그냥 (인풋과 함께 말아감긴) 필터(혹은 커넬)이라고 흔히들 지칭하는 이유이다. 

![이미지](http://cs231n.github.io/assets/cnn/weights.jpeg)

> 예시 필터들은 Krizhevsky et al. 의 논문에서 학습된 것들이다. 96개 필터 각각이 11x11x3 사이즈를 가지고 있고,  _개당 하나의 깊이 슬라이스에 55*55개의 뉴런들을 공유하고 있다._ 파라미터 공유 가정이 나름 합리적이라고 느껴지지 않는가? 어떤 이미지의 특정 위치에서 수평의 모서리/엣지를 발견하는게 중요하다면, 그 특징은 다른 위치에서도 왠지 중요해야 할 것만 같다 -- 이미지들의 translationally-invariant 구조 때문에. (약간 원판불변의 법칙 같은 느낌적인 느낌..?) 그러니까 Conv layer 아웃풋 볼륨의 모든 55*55 지점마다 수평 엣지를 발견하기 위해 학습을 또하고 또하고 또할 필요가 없는 것이다.  


기억하라! 파라미터 공유 가정이 항상 말이 되는 것만은 아니다. ConvNet에 넣을 인풋 이미지들이 특정한 위치에 센터를 가진 구조라면, 이미지의 한쪽에서와 다른쪽에서 얻는 특징들이 완전히 다를 것이다. 하나 유용한 예제는, 인풋들이 얼굴이고, 이미지의 중앙이 중심점인 경우이다. 너는 아마 눈, 머리카락 별로 다 다른 공간(폭x높이)에서 학습될 거라고 생각하겠지? 그런 경우에는, 그냥 파라미터 공유를 버리고 레이어를 단순하게 Locally-connected 레이어라고 부른다. 

**넘파이 예제들**

위의 이야기들을 좀 더 구체화하기 위해 같은 말을 코드와 예시로 풀어보자. 인풋 볼륨이 x 라는 넘파이 배열이라고 가정한다. 

(x, y)좌표에 있는 depth 열은 `X[x,y:]` 액티베이션이다.
depth 슬라이스, 혹은 depth 특정지점 d에서의 activation map, 은 `X[:,:,d]` 액티베이션 이다.

**Conv Layer 예시**

인풋 볼륨 x 가 X.shape: (11,11,4) 라는 모양을 가졌다고 생각하자. 그리고 zero padding=0, filter size =5, stride=2라고 생각한다. 그렇다면 아웃풋 볼륨은 spatial 사이즈가 `(11-5)/2+1 =4` , 즉 폭과 넓이가 4인 볼륨을 내뱉을 것이다. 아웃풋 볼륨 V에서의 액티베이션 맵은 다음과 같을 것이다. (몇개만 계산해서 보여준다.)

```
V[0,0,0] = np.sum(X[:5,:5,:] * W0) + b0
V[1,0,0] = np.sum(X[2:7,:5,:] * W0) + b0
V[2,0,0] = np.sum(X[4:9,:5,:] * W0) + b0
V[3,0,0] = np.sum(X[6:11,:5,:] * W0) + b0
```

넘파이에서는 * 라는 오퍼레이션 기호가 배열끼리의 원소별 곱셈을 의미한다는 것을 기억해내야 한다. 또한, 가중치 벡터 W0는 그 뉴런에서의 가중치 벡터이고, b0 은 편향이다. 여기서, 필터사이즈는 5, 인풋볼륨의 깊이는 4이기 때문에, W0은 W0.shape: (5,5,4) 모양일 것이다. 각 점마다, 이전에 평범한 신경망에서 보았던 것처럼 내적을 계산하는 것이다. 그리고 보시다시피 우리는 같은 가중치와 편향 값들을 사용하고 있고, 폭을 따라서 차원이 2만큼씩 커지고 있다 (stride). 

아웃풋 볼륨에 두번째 액티베이션 맵을 구성한다면 이렇다.
```
V[0,0,1] = np.sum(X[:5,:5,:] * W1) + b1
V[1,0,1] = np.sum(X[2:7,:5,:] * W1) + b1
V[2,0,1] = np.sum(X[4:9,:5,:] * W1) + b1
V[3,0,1] = np.sum(X[6:11,:5,:] * W1) + b1
V[0,1,1] = np.sum(X[:5,2:7,:] * W1) + b1 (example of going along y)
V[2,3,1] = np.sum(X[4:9,6:11,:] * W1) + b1 (or along both)
```

여기서는 V의 두번째 깊이 차원의 인덱스(인덱스 값 1) 를 건드리고 있는 걸 볼 수 있다. 왜 이러는 거냐면, 우리는 지금 두번째 액티베이션 맵을 계산하고 있고, 다른 파라미터 셋(집합)인 W1을 쓰고 있기 때문이다. 이 예시에서는 간략하게 표현하기 위해 Conv Layer의 다른 오퍼레이션을 생략했는데, 그 생략된 오퍼레이션 안에는 V아웃풋 배열의 다른 부분들의 계산 수행이 포함되어 있을 것이다. 추가적으로, 액티베이션 맵들은 ReLU와 같은 액티베이션 함수에 원소별로 투입된다. 그렇지만 여기다가는 안썼지롱.

**요약** 

Conv Layer를 요약해보자.

- W1 x H1 x D1 볼륨사이즈를 인풋으로 받는다.
- 네 종류의 하이퍼 파라미터가 필요하다
   - 필터의 개수 K
   - sptial (폭*높이) 범위 F
   - stride S
   - zero Padding 개수 P
- W2 x H2 x D2 아웃풋 볼륨 사이즈를 만들어 낸다. 
    - `W2 = (W1 - F + 2P)/S +1`
    - `H2 = (H1 - F + 2P)/S +1`
    - 폭과 높이는 대칭적으로 똑같이 계산된다.
    - D2 = K
- 파라미터 공유에 의해, 각 필터마다 `F*F*D1` 의 가중치 개수를 가지고, 총 `(F*F*D1)*K` 가중치와 K 편향 개수를 가진다.
- 인풋 볼륨, stride S에 대해서 d번째 필터로 컨볼루션을 하고 d번째 편향으로 상쇄시켜준 결과가 아웃풋 볼륨에서 d번째 깊이 슬라이스 (W2*H2 부분의 깊이 차원)이다.

하이퍼파라미터는 보통 Filter = 3, Stride =1, zeroPadding =1 이렇게 잡고 시작한다. 하지만, 이런 하이퍼 파라미터들을 조정하는 몇 가지 규칙같은 것이 있다. 아래의 ConvNet Architectures 단락을 보면 될 것.

**컨볼루션 데모**

아래는 ConV Layer가 돌아가고 있는 모습이다. 3차원 볼륨들은 시각화하기 어렵기 때문에 모든 볼륨들 (인풋은 파랑, 가중치는 빨강, 아웃풋은 초록)은 각 depth 슬라이스가 행 단위로 쌓여 있도록 표현했다. 인풋 볼륨은 사이즈가 W1 =5, H1=5, D1 = 3 이고, Conv Layer 파라미터들이 K =2 ,F=3, S=2, P=1이다. 이 말은, 우리가 2개의 필터를 가지고 있고, 각 필터의 사이즈는 3x3이며, Stride로 2를 적용할 것이라는 소리다. 그래서 아웃풋 볼륨 사이즈는 (5-3+2)/2+1 =3 의 폭*높이 사이즈를 같게 된다. 또한 패딩=1 이 인풋 볼륨에 적용되어 인풋 볼륨의 바깥 모서리들을 0으로 만들었다. 이 시각화 데모는 아웃풋 액티베이션 (초록)을 반복하며 돌아가는데, 그때 그때 하이라이트되는 아웃풋 원소는 -- 하이라이트된 파랑 인풋 지역 * 빨강 필터 들의 원소별 곱을 다 더한 후, 편향까지 적용한 결과이다.


### Pooling Layer

### Normalization Layer

### Fully-connected layer

### Converting FC layers to CONV layers

## ConvNet Architectures

### Layer Patterns

### Layer Sizing Patterns

### Case Studies

### Computational Considerations

## Additional Resources
