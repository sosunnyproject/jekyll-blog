---
layout: default
---


> Translating http://cs231n.github.io/convolutional-networks/ to Korean 스탠포드강의노트 한국어번역중

# Convolutional Neural Networks (CNNs/ConvNets)

CNN은 우리가 이전 장에서 본 일반적인 뉴럴 네트워크와 흡사하다. CNN은 학습하며 업데이트 되는 편향치(bias)와 가중치(weight)를 가진 뉴런으로 구성되어 있다. 

각 뉴런은 몇가지의 인풋을 받은 후, 행렬의 내적(dot product)를 수행하고, 원한다면 non-linearity를 취해줄 수 있다. 이 뉴런들로 큰 하나의 네트워크를 만든다 할지라도, 네트워크는 여전히 하나의(single) 미분가능한 스코어 함수이다: 한쪽은 원본 이미지 픽셀, 다른쪽은 클래스 스코어. 더불어, CNN에서도 마지막 레이어 (fc layer)에 손실 함수 (svm, softmax 등)를 적용한다. 일반적인 뉴럴 네트워크에 썼던 팁/트릭/기법들을 거의 그대로 적용할 수 있다고 생각하면 된다. 

그럼 뭐가 다른걸까? ConvNet 구조에서는 한가지 확실한 가정을 해두고 가야한다. "인풋은 이미지이다. 그리고 우리는 그 이미지들의 특정 속성들을 구조로 인코딩할 수 있어야 한다." 이게 가능해야지 우리가 forward function 을 더 효율적으로 실행할 수 있고, 네트워크의 수많은 파라미터를 확 줄일 수 있다. 

## 구조 훑어보기

#### _일반적인 뉴럴 넷 (신경망)을 기억해보자._
우리가 이전 장에서 보았던 것처럼, 뉴럴 네트워크는 벡터 하나를 인풋으로 받고, 그것을 여러 hidden 레이어들에 통과시켜서 변형한다. 각 hidden 레이어는 여러 뉴런들의 집합으로 구성되어 있다. 이 때 이 hidden 레이어의 뉴런 하나하나는 그 전 레이어의 뉴런들에 모두 빠짐없이 연결되어 있다. 그리고 같은 레이어 안에 있는 뉴런들끼리는 전혀 연결되어 있지 않다. 마지막 fully-connected 레이어는 'output layer' (결과값 레이어)로 불리며, 분류 문제(classification)에서는 이 최종 레이어가 클래스 스코어를 나타낸다. 

일반적인 뉴럴 넷은 큰 이미지 전체 사이즈로 잘 확장할 수가 없다. CIFAR-10에서 이미지들은 32x32x3 (32폭, 32높이, 3 칼라 채널)사이즈 정도 밖에 안된다. 그래서 첫 hidden 레이어에 있는 한개의 뉴런 (fully-connected neuron: 아까 위에서 뉴런은 그 전 애들과 다 연결되어 있다고 했으니까)은 32x32x3 = 3072 개의 가중치를 갖는다. 이 정도면 감당할 수 있을 것처럼 보이는가? 하지만 이런 fully-connected 구조(폭x높이x칼라 다 곱하고 뉴런끼리 다 이어주는 구조...)는 더 큰 이미지 사이즈에는 적용할 수가 없다. 예를 들어, 좀 더 흔히 사용되는 이미지 사이즈는 더 클 것이고, 200x200x3이라고 가정해보자. 그렇다면 200x200x3 = 120,000개의 가중치를 갖는 뉴런이 생기고, 그러한 뉴런들이 모인다면 순식간에 파라미터 개수는 불어날 것이다. 즉, 이러한 full connectivity 는 소모적이며, 수많은 파라미터는 멀지않아 오버피팅을 자초할 것이다.

#### _3차원 볼륨의 뉴런들_

CNN은 _인풋이 이미지로 이루어져 있고 이미지들은 나름 합리적으로 구조를 이루고 있다_ 는 점을 유리하게 이용한다. 일반적인 뉴럴 네트워크와 다르게, ConvNet의 뉴런들은 3차원에 배열되어 있다: 폭, 넓이, 깊이 (여기서 깊이는 활성 volume의 3번째 차원이며, 전체 신경망의 깊이/네트워크의 전체 레이어 개수가 아니다). 예를 들어, CIFAR-10에서 구해오는 인풋 이미지들은 **input volume of activation** 이며, volume은 32x32x3 의 차원을 가지고 있다. 잠시 후에 같이 보겟지만, 레이어의 뉴런들은 이전 레이어에 부분적으로만 연결될 것이다. 그전처럼 fully-connected 되는 것이 아니라. 나아가, CIFAR-10 
을 인풋으로 돌린 네트워크의 마지막 최종 레이어는 1x1x10 차원을 가지게 된다. 왜냐하면 ConvNet 구조의 끝에서는 이미지 통짜 하나를 스코어 클래스를 나타내는 벡터 하나로 줄여버리기 때문이다. 이 때 이 단일 벡터는 depth 차원을 따라서 배열되어 있는 형태이다. (depth 차원의 사이즈를 따른다는 의미로 해석하면 될 것 같다.)

[이미지](http://cs231n.github.io/assets/nn1/neural_net2.jpeg)

> 좌: 일반적인 3층의 신경망 구조. 

> 우: ConvNet 는 자기 뉴런들을 3차원으로 배열한다 (폭, 넓이, 깊이). ConvNet의 각 레이어는 3D 인풋 볼륨을 뉴런들이  활성화된 3D 아웃풋 볼륨으로 바꿔준다. 이 예시에서, 빨강 인풋 레이어가 이미지이고, 빨강의 폭과 넓이는 이미지의 사이즈이다. 그리고 깊이는 빨, 초, 파 칼라 채널이다. 

>> ConvNet은 레이어로 이루어져 있다. 각 레이어는 간단한 API이다. 3차원 인풋을 3차원 아웃풋으로 바꿔준다. 파라미터를 가지고 있을 수도, 아닐 수도 있는, 몇몇 미분 가능한 함수를 이용해서.

## Layers used to build ConvNets ConvNets 만드는 데 필요한 레이어들
위에서 설명했듯이, 간단한 ConvNet (CNN 지칭)은 레이어들의 연속이다. 그리고 각 레이어는 미분 함수를 통해서 _활성화의 한 볼륨_ 을 또다른 것으로 변환시킨다. 우리는 3개의 주요 레이어 타입을 ConvNet 구조에 사용한다: Convolutional Layer, Pooling layer, Fully Connected Layer (바로 일반적인 신경망 네트워크에서 사용하였듯이). 우리는 이런 레이어들을 쌓아서 완전한 ConvNet 구조를 만들 것이다.

**구조 예시: 훑어보기**
아래에서 더 자세히 살펴보겠지만, CIFAR-10 분류를 위한 간단한 ConvNet의 구조는 이렇게 되시겠다: 인풋 - Conv - Relu - Pool - Fc.

자세한 설명:
- 인풋 [32x32x3] 은 이미지의 raw 픽셀값들을 가지고 있다. 이 경우, 폭 32, 높이 32, 색 채널 3이다.
- ConV 레이어는 뉴런들의 아웃풋을 계산한다. 뉴런들은 인풋의 로컬 영역에 연결되어 있고, 각 뉴런은 그들의 가중치와 인풋 로컬영역 간의 행렬 내적곱을 계산한다. 그래서 우리가 만약 12개의 필터를 사용한다치면 [32x32x12] 사이즈의 볼륨을 얻을 것이다.
- RELU 레이어는 elementwise (원소별) 활성화 함수를 사용하는데, max(0,x)계산은 0을 경계점으로 만들어버린다. 이 때, 볼륨의 사이즈(32x32x12)는 바뀌지 않는다.
- 풀링 레이어는 이미지 사이즈를 줄여주는 역할을 한다. 폭과 넓이로 이뤄진 공간 차원을 따라서 사이즈를 축소시켜서 32x32x12를 16x16x12로 바꾸듯이 더 작게 만들어준다.
- FC 레이어는 클래스 스코어를 계산해서 1x1x10 사이즈의 볼륨을 생성한다. CIFAR-10에서 10가지 카테고리가 있는 것처럼, 10개의 숫자들은 클래스 스코어에 해당한다. 일반 뉴럴 네트워크에서 하던 것처럼 (그리고 fully-connected라는 이름이 암시하듯이) 이 레이어의 각 뉴런은 이전 볼륨의 모든 숫자에 연결되어 있다.

이러한 방식으로 ConveNet들은 레이어 하나하나를 거치며 원본 이미지 픽셀 값을 최종 클래스 스코어로 변환한다. 단, 어떤 레이어는 파라미터를 가지고 있고 어떤 것은 그렇지 않다는 것을 주의해라. 특히, ConV/FC 레이어들은 변환을 수행할 때 활성화뿐만 아니라 (가중치와 편향의) 파라미터에 대한 함수들을 사용한다. 다른말로 하자면, RELU/POOL 레이어는 고정 함수를 실행한다. CONV/FC 의 파라미터들은 gradient descent로 인해 학습이 될 것이다. 그렇게 학습을 함으로써, ConvNet이 계산한 클래스 스코어는 트레이닝 데이터 셋에 있는 각 이미지의 클래스 라벨과 동일해야 한다.

요약을 하자면:
- ConvNet 구조는 이미지 볼륨을 어떤 아웃풋 볼륨 (예, 점수 값 보유)으로 변환시켜주는 레이어들의 조합 중 가장 단순한 예시이다.
- 레이어에는 몇가지 기억해둘 타입이 있다: ConV/FC/Relu/Pool이 그 중 제일 유명하다.
- 각 레이어는 3차원 인풋 볼륨을 받고, 미분 함수를 통해서 3차원 아웃품 볼륨을 만든다.
- CONV/FC는 파라미터가 있지만, RELU/Pool은 없다.
- 어떤 레이어는 추가적으로 초파라미터를 가지고 있다. (CONV/FC/Pool은 yes, Relu는 no..)

[이미지](http://cs231n.github.io/assets/cnn/convnet.jpeg)

> ConvNet 구조 에시의 활성화를 보여주는 그림이다. 초기 불륨은 원본 raw 이미지 픽셀 (좌) 을 보유하고 있고, 마지막 볼륨은 클래스 스코어 (우)를 가지고 있다. 일련의 과정을 따라 활성화되는 각 볼륨은 여기서 한 열로 보여지고 있다. 마지막 레이어의 볼륨은 각 클래스에 대한 스코어를 가지고 있지만 이 예시에서는 5개의 고득점 클래스만 시각화했다. 본 웹 데모의 완성판은 우리 웹사이트에서 볼 수 있다. 여기저 보여주는 구조는 작은 VGG 넷 (나중에 설명할 거다)을 쓰고 있다.

우리는 이제 각 레이어와 그들의 하이퍼 파라미터 및 연결고리에 대해서 자세히 알아볼 거다.

### Convolutional 레이어
- Conv 레이어는 Conv 네트어크에서 대부분의 무거운 계산을 책임지는 핵심 요소이다.

**뇌구조 이야기 없이 훑어보기**
우선 Conv Layer에 대해서 뇌구조 비유법은 집어치우고 이야기를 해보자. ConV 레이어의 파라미터는 학습가능한 필터의 집합으로 이루어져 있다. 각 필터는 폭과 높이로 따졌을 때는 작지만 인풋 볼륨 깊이만큼 확장된다/늘어난다. 예를 들어, 보통 첫번째 레이어에 적용하는 필터는 5x5x3 (폭x길이x칼라채널개수이자-깊이)사이즈를 가졌다. forward 계산을 할 때, 각 필터를 인풋 볼륨의 폭과 높이에 대해 슬라이드 시킨다 (더 정확히는 말아 간다 라는 단어가 맞다) 그리고 필터의 값과 인풋 값을 내적한다. 이 슬라이딩 과정에서 우리는 2차원의 활성화 매핑값을 만드는데 각 위치에서 (5x5 마다의 위치) 필터와의 매핑값 결과가 담겨있다.직관적으로 생각한다면, 네트워크는 어떤 특정한 시각 정보를 발견했을 때 활성화되는 필터를 학습할 것이다. 초반의 레이어에서는 엣지(테두리 선)의 방향이나 색깔 뭉탱이를 보다가 나중에는 벌집 모양 전체 혹은 바퀴 모양의 패턴 등을 특징으로 발견할 것이다. 이제 우리는 각 ConV 레이어에 적용한 전체 필터 집합/모음을 가지게 되고 (12 필터), 각 필터는 각기 다른 2차원 활성화 매핑값을 만든다. 우리는 이 활성화 매핑을 깊이를 따라 쌓아서 전체 아웃풋 볼륨을 만들 것이다.

**뇌과학 관점**
네가 정 뇌/뉴런 비유법을 원한다면 알려주지.. 3차원 아웃풋 볼륨의 각 *entry* 는 뉴런의 아웃풋이라고 생각해볼 수도 있다. 어떤 뉴런? 인풋 이미지에서 작은 부분 하나만 보고 좌우에 있는 모든 뉴런과 그 파라미터를 공유하는 아이일 것이다 (왜냐하면 그 숫자들은 같은 필터를 적용해서 나오는 결과값이기 때문에). 우리는 이제 뉴런들의 연결성, 공간에서의 배치도, 공유되는 파라미터들에 대해서 알아볼 것이다.

**지역적 연결성** (너와 나의 연결고리..)
이미지와 같은 고차원 인풋을 가지고 놀 때, 위에서 보앗듯이, 이전 볼륨의 모든 뉴런에다가 지금의 뉴런을 다 연결시키는 건 비실용적인 짓이다. 대신, 우리는 각 뉴런을 인풋 볼륨의 작은 부분만이랑 연결시키고 싶다. 이 연결성을 이미지 공간에 대해서 확장한 것이 뉴런(뉴런의 사이즈는 필터의 사이즈와 같다.)의 receptive field라 불리는 하이퍼 파라미터이다. 깊이 축을 따라 확장한다면 인풋 볼륨의 깊이와 같아지겠지? 이렇게 폭x높이 차원에 대하는 방식과 깊이를 대하는 방식이 다르다는 점, 이 비대칭의 성질은 두번 강조해도 시원찮다. 연결고리는 폭x넓이에 대해서는 지역적이지만, 깊이에 대해서는 전체 깊이 사이즈와 연결되어 있다.

예시1. 32x32x3 사이즈의 인풋 볼륨이 있다고 하자. (CIFAR-10의 RGB 이미지가 그렇다.) 필터 사이즈가 만약 5x5 라면, ConV Layer의 각 뉵런은 5x5x3 사이즈 부분에 대한 가중치를 가져서 토탈 5*5*3 = 75(가중치) + 1(편향) = 76개의 파라미터를 갖는다. 이 때, 이미지의 깊이가 3이니, 깊이 축을 따라 뉴런의 연결고리가 확장되는 사이즈는 반드시 3이어야 한다.

예시2. 16x16x20 사이즈의 인풋이 있다고 생각하자. 필터의 크기는 3x3이다. ConvLayer에 있는 모든 뉴런의 각각 3*3*20 = 180 개의 연결고리를 가지고 있다. 이때 저체 이미지의 3x3 폭x높이 사이즈 마다 한 뉴런이랑 매핑되어 있고, 한 뉴런의 깊이는 20이다.

[이미지](http://cs231n.github.io/assets/cnn/depthcol.jpeg)

> 좌: 빨강색이 인풋 볼륨, ConV의 첫 레이어에 있는 뉴런의 볼륨. 이 레이어의 각 뉴런은 인풋 볼륨의 폭x높이에 대해 지역적으로만(필터 사이즈 만큼씩만) 연결되어 있다. 기억하자: 깊이를 따라 여러 뉴런들이 있고 (여기서는 5), 다 인풋의 같은 지역 부분을 바라보고 있다 - 깊이 열에 대한 설명은 아래에서 이야기하자.

> 우: 뉴럴 네트워크에서 나왔던 뉴런 계산과정은 바뀌지 않았다. 여전히 그들의 가중치들과 인풋의 내적을 계산하고 non-linearity (비선형)을 거친다. 하지만 그들의 연결고리의 범위만 지역으로 제한된 것이다.

**Spatial Arrangement. 공간적 배치** 
Conv 의 각 뉴런이 인풋 볼륨과 연결되어 있다고 몇번을 말했는지 모른다. 하지만 우리는 아직 얼마나 많은 뉴런들이 아웃풋 볼륨에 있는지 혹은 어떻게 배치되어 있는지는 이야기하지 않았다. 아웃풋 볼륨을 결정하는 세가지 파라미터는 다음과 같다: 깊이, 스트라이드(간격), 제로 패딩(0여백)

1. 아웃풋 볼륨의 **깊이** 는 하이퍼 파라미터이다. 깊이는 우리가 사용할 필터의 개수에 상응하는데, 각 필터는 인풋에서 각기 다른 부분을 보고 있다. 예를 들어, 첫 Conv 레이어가 원본 이미지를 인풋으로 받았다. 그리고 깊이 부분에 들어있는 뉴런들은 다양한 방향을 가진 엣지/색깔 뭉탱이들의 존재에 반응하며 활성화될 수도 있다. 우리는 이미지의 같은 로컬부분을 바라보고 있는 뉴런 뭉태기들을 깊이 열 이라고 지칭할거다. (어떤 인간들은 fibre라는 용어를 선호한다. 니맴니맴 내맴내맴)

2. 두번째, 우리는 반드시! 필터를 슬라이드시킬 기준이 되는 스트라이드(간격)를 정해놓고 시작해야 한다. 스트라이드가 1이면 우리는 필터들을 한 번에 한 픽셀씩만 움직인다 (슬라이드시킨다). 스트라이드가 2이면 필터는 한 번에 두 픽셀을 점프해서 다음 로컬 영역으로 넘어간다. (3혹은 그 이상으로 스트라이드 값을 정하는 경우는 드물다.) 이렇게 2씩 점프한다면 아웃풋 볼륨의 폭x높이를 더 작은 사이즈로 만들어 낸다.

3. 아래서 곧 보겠지만, 가끔 인풋 볼륨의 모서리를 따라서 패딩(여백)을 0값들로 채워주는 게 편할 때가 있다. 이 제로 패딩의 사이즈가 하이퍼 파라미터이다. 제로 패딩의 좋은 특징은 이걸 이용해서 아웃풋 볼륨의 spatial size (폭x높이) 사이즈를 조절할 수 있다는 것이다. (잠시 후에 알려주겠지만, 거의 대부분은 인풋 볼륨의 spatial 폭x높이 사이즈를 원본이랑 똑같이 유지할 수 있도록 패딩 사이즈를 준다. 그래야 인풋과 아웃풋의 폭x높이 사이즈가 같아지니까.)

인풋 볼륨 사이즈의 함수(W), Conv 레이어 뉴런들의 필터(혹은 receptive field) 사이즈(F), 적용한 스트라이드 값(S), 모서리에 붙여 쓴 제로 패딩(P)의 양 -- 우리는 이것들을 가지고 아웃풋의 spatial 사이즈를 계산할 수 있다. 얼마나 많은 뉴런이 끼워맞춰지는지를 알고 싶으면 (W-F+2P)/S + 1 수식을 이용하면 된다고 네 뇌를 설득해도 무방하다 (그냥 외워도 된다는 소리다.) 예를 들어, 7x7 인풋, 스트라이드 1, 패딩0 3x3 필터를 쓴다면
(7 - 3 + 2* 0) / 1 + 1 = 4+1 = 5
계산해서 5x5 아웃풋 사이즈를 얻는다.
스트라이드 2라고 가정하면, 3x3 아웃풋이 나온다.
(이 대입 계산 정도는 님이 하시길...)

[이미지](http://cs231n.github.io/assets/cnn/stride.jpeg)

> 공간 배치의 묘사도. 이 예시에서는 공간 차원이 하나, x 축밖에 없고, 하나의 뉴런당 필터 사이즈가 3, 인풋 사이즈는 5, 제로 패딩 1.

> 좌: 인풋에 스트라이드 1 이 적용된 뉴런 --> (5-3+2)/1 +1 =5 아웃풋 사이즈가 나왔다.

> 우: 스트라이드 값을 2를 줬더니, 3이 나왔다. 스트라이드 3값은 쓸수가 없다 - 인풋 볼륨에 깔끔하게 적용이 안되니까. 수식으로 생각해보면, (5-3+2)=4 는 3으로 나눌 수가 없짜나?

> 뉴런 가중치들은 [1,0,-1] (최 우측) 이고, 편향치는 제로라고 생각하자. 이 가중치들은 노랑 뉴런 하나하나에 다 적용된다. (파라미터 공유에 대해서는 아래에서 설명할거다.)

### Pooling Layer

### Normalization Layer

### Fully-connected layer

### Converting FC layers to CONV layers

## ConvNet Architectures

### Layer Patterns

### Layer Sizing Patterns

### Case Studies

### Computational Considerations

## Additional Resources
